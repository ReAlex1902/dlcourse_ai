{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week 06 - RNNs, part 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U6O2DwKpqHm",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {}
      },
      "source": [
        "!pip3 -qq install torch #==0.4.1\n",
        "!pip3 -qq install bokeh #==0.13.0\n",
        "!pip3 -qq install gensim #==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn #==0.20.2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c0c30aa3-9731-4c7c-f58b-18444bb48993"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "95d006fb-a650-4fc2-c3ce-65a3032c3a7d"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "2b8f10ce-0bc1-4604-a118-3c9f50e01c1a"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e5232a7e-c64f-4ddb-b5f7-d85802deb75c"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'PRON', 'ADV', 'NOUN', 'VERB', 'ADJ', 'NUM', 'PRT', '.', 'ADP', 'DET', 'CONJ', 'X'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "da9e9d7e-08e3-4ea1-fd58-1de5ec52fa06"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1cbf66ee-158a-4c0d-8f3e-75b07d86bb9d"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "661772ba-c306-4813-d0e2-4cb967efcd91"
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "33df59fb-99c1-441f-b341-84ca8df9a0ad"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "10a39df6-7f24-4dd4-a555-b35d7093080a"
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers = lstm_layers_count)\n",
        "        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, self.hidden = self.lstm(embeds)\n",
        "        tag_res = self.hidden2tag(lstm_out)\n",
        "        # tag_res = F.softmax(tag_res)\n",
        "\n",
        "        return tag_res"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "754772c4-3186-4534-e7fa-88fa312b7b10"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "preds = torch.argmax(logits, dim = -1)\n",
        "mask = (y_batch != 0).float() ## for deleting the padding\n",
        "\n",
        "correct_preds = ((preds == y_batch).float() * mask).sum().item() ## correct predictions\n",
        "total_preds = (y_batch != 0).float().sum().item()\n",
        "print(correct_preds / total_preds)\n",
        "# <calc accuracy>"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07608695652173914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0fabd62e-ea53-4d01-b4ae-ab1c05259a17"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = 0\n",
        "for i, elem in enumerate(logits):\n",
        "    loss += criterion(elem, y_batch[i])\n",
        "    \n",
        "loss"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(83.4519, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = 0\n",
        "                for i, elem in enumerate(logits):\n",
        "                    loss += criterion(elem, y_batch[i])\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                mask = (y_batch != 0).float()\n",
        "                preds = torch.argmax(logits, dim = -1)\n",
        "                preds = ((preds == y_batch).float() * mask).sum().item()\n",
        "                total = mask.sum().item()\n",
        "                cur_correct_count, cur_sum_count = preds, total\n",
        "\n",
        "                # preds = torch.argmax(logits, dim=-1)\n",
        "                # mask = (y_batch != 0).float()\n",
        "                \n",
        "                # cur_correct_count, cur_sum_count = ((preds == y_batch).float() * mask).sum().item(), mask.sum().item()\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80561da3-6faf-40c8-e616-8395c660ed99"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 50] Train: Loss = 19.84504, Accuracy = 71.92%: 100%|██████████| 572/572 [00:20<00:00, 27.79it/s]\n",
            "[1 / 50]   Val: Loss = 9.43964, Accuracy = 85.33%: 100%|██████████| 13/13 [00:00<00:00, 32.63it/s]\n",
            "[2 / 50] Train: Loss = 6.22865, Accuracy = 89.87%: 100%|██████████| 572/572 [00:20<00:00, 27.67it/s]\n",
            "[2 / 50]   Val: Loss = 6.85387, Accuracy = 89.81%: 100%|██████████| 13/13 [00:00<00:00, 31.57it/s]\n",
            "[3 / 50] Train: Loss = 4.17734, Accuracy = 93.21%: 100%|██████████| 572/572 [00:19<00:00, 29.07it/s]\n",
            "[3 / 50]   Val: Loss = 6.12456, Accuracy = 91.43%: 100%|██████████| 13/13 [00:00<00:00, 32.76it/s]\n",
            "[4 / 50] Train: Loss = 3.16760, Accuracy = 94.79%: 100%|██████████| 572/572 [00:19<00:00, 29.32it/s]\n",
            "[4 / 50]   Val: Loss = 5.87927, Accuracy = 92.21%: 100%|██████████| 13/13 [00:00<00:00, 33.04it/s]\n",
            "[5 / 50] Train: Loss = 2.52218, Accuracy = 95.80%: 100%|██████████| 572/572 [00:18<00:00, 30.74it/s]\n",
            "[5 / 50]   Val: Loss = 5.68936, Accuracy = 92.79%: 100%|██████████| 13/13 [00:00<00:00, 37.90it/s]\n",
            "[6 / 50] Train: Loss = 2.05237, Accuracy = 96.57%: 100%|██████████| 572/572 [00:18<00:00, 31.03it/s]\n",
            "[6 / 50]   Val: Loss = 5.68305, Accuracy = 92.96%: 100%|██████████| 13/13 [00:00<00:00, 37.70it/s]\n",
            "[7 / 50] Train: Loss = 1.68926, Accuracy = 97.16%: 100%|██████████| 572/572 [00:19<00:00, 28.61it/s]\n",
            "[7 / 50]   Val: Loss = 5.70839, Accuracy = 93.14%: 100%|██████████| 13/13 [00:00<00:00, 31.44it/s]\n",
            "[8 / 50] Train: Loss = 1.39701, Accuracy = 97.64%: 100%|██████████| 572/572 [00:19<00:00, 29.86it/s]\n",
            "[8 / 50]   Val: Loss = 5.86987, Accuracy = 93.24%: 100%|██████████| 13/13 [00:00<00:00, 37.14it/s]\n",
            "[9 / 50] Train: Loss = 1.15336, Accuracy = 98.03%: 100%|██████████| 572/572 [00:19<00:00, 29.32it/s]\n",
            "[9 / 50]   Val: Loss = 6.17301, Accuracy = 93.25%: 100%|██████████| 13/13 [00:00<00:00, 33.05it/s]\n",
            "[10 / 50] Train: Loss = 0.95681, Accuracy = 98.39%: 100%|██████████| 572/572 [00:18<00:00, 30.42it/s]\n",
            "[10 / 50]   Val: Loss = 6.37027, Accuracy = 93.18%: 100%|██████████| 13/13 [00:00<00:00, 37.93it/s]\n",
            "[11 / 50] Train: Loss = 0.78530, Accuracy = 98.70%: 100%|██████████| 572/572 [00:18<00:00, 31.40it/s]\n",
            "[11 / 50]   Val: Loss = 6.62893, Accuracy = 93.19%: 100%|██████████| 13/13 [00:00<00:00, 40.09it/s]\n",
            "[12 / 50] Train: Loss = 0.64012, Accuracy = 98.95%: 100%|██████████| 572/572 [00:20<00:00, 28.59it/s]\n",
            "[12 / 50]   Val: Loss = 6.96986, Accuracy = 93.08%: 100%|██████████| 13/13 [00:00<00:00, 31.76it/s]\n",
            "[13 / 50] Train: Loss = 0.51674, Accuracy = 99.17%: 100%|██████████| 572/572 [00:19<00:00, 29.20it/s]\n",
            "[13 / 50]   Val: Loss = 7.36385, Accuracy = 93.04%: 100%|██████████| 13/13 [00:00<00:00, 37.96it/s]\n",
            "[14 / 50] Train: Loss = 0.41762, Accuracy = 99.34%: 100%|██████████| 572/572 [00:19<00:00, 29.27it/s]\n",
            "[14 / 50]   Val: Loss = 7.71462, Accuracy = 93.00%: 100%|██████████| 13/13 [00:00<00:00, 32.04it/s]\n",
            "[15 / 50] Train: Loss = 0.33339, Accuracy = 99.50%: 100%|██████████| 572/572 [00:19<00:00, 30.01it/s]\n",
            "[15 / 50]   Val: Loss = 8.07219, Accuracy = 92.95%: 100%|██████████| 13/13 [00:00<00:00, 38.47it/s]\n",
            "[16 / 50] Train: Loss = 0.26790, Accuracy = 99.60%: 100%|██████████| 572/572 [00:18<00:00, 30.73it/s]\n",
            "[16 / 50]   Val: Loss = 8.36625, Accuracy = 92.92%: 100%|██████████| 13/13 [00:00<00:00, 35.78it/s]\n",
            "[17 / 50] Train: Loss = 0.21916, Accuracy = 99.69%: 100%|██████████| 572/572 [00:19<00:00, 29.99it/s]\n",
            "[17 / 50]   Val: Loss = 8.65984, Accuracy = 92.84%: 100%|██████████| 13/13 [00:00<00:00, 36.48it/s]\n",
            "[18 / 50] Train: Loss = 0.18404, Accuracy = 99.74%: 100%|██████████| 572/572 [00:18<00:00, 30.59it/s]\n",
            "[18 / 50]   Val: Loss = 9.01718, Accuracy = 92.87%: 100%|██████████| 13/13 [00:00<00:00, 37.63it/s]\n",
            "[19 / 50] Train: Loss = 0.15453, Accuracy = 99.78%: 100%|██████████| 572/572 [00:19<00:00, 29.63it/s]\n",
            "[19 / 50]   Val: Loss = 9.39740, Accuracy = 92.83%: 100%|██████████| 13/13 [00:00<00:00, 32.81it/s]\n",
            "[20 / 50] Train: Loss = 0.13509, Accuracy = 99.80%: 100%|██████████| 572/572 [00:19<00:00, 29.67it/s]\n",
            "[20 / 50]   Val: Loss = 9.77892, Accuracy = 92.78%: 100%|██████████| 13/13 [00:00<00:00, 34.62it/s]\n",
            "[21 / 50] Train: Loss = 0.13014, Accuracy = 99.80%: 100%|██████████| 572/572 [00:18<00:00, 30.67it/s]\n",
            "[21 / 50]   Val: Loss = 9.94080, Accuracy = 92.82%: 100%|██████████| 13/13 [00:00<00:00, 38.45it/s]\n",
            "[22 / 50] Train: Loss = 0.12590, Accuracy = 99.80%: 100%|██████████| 572/572 [00:19<00:00, 28.88it/s]\n",
            "[22 / 50]   Val: Loss = 10.53540, Accuracy = 92.71%: 100%|██████████| 13/13 [00:00<00:00, 31.67it/s]\n",
            "[23 / 50] Train: Loss = 0.12208, Accuracy = 99.80%: 100%|██████████| 572/572 [00:19<00:00, 29.96it/s]\n",
            "[23 / 50]   Val: Loss = 10.48385, Accuracy = 92.74%: 100%|██████████| 13/13 [00:00<00:00, 34.65it/s]\n",
            "[24 / 50] Train: Loss = 0.10954, Accuracy = 99.82%: 100%|██████████| 572/572 [00:19<00:00, 30.00it/s]\n",
            "[24 / 50]   Val: Loss = 11.02950, Accuracy = 92.76%: 100%|██████████| 13/13 [00:00<00:00, 32.86it/s]\n",
            "[25 / 50] Train: Loss = 0.10290, Accuracy = 99.83%: 100%|██████████| 572/572 [00:18<00:00, 30.23it/s]\n",
            "[25 / 50]   Val: Loss = 11.13942, Accuracy = 92.75%: 100%|██████████| 13/13 [00:00<00:00, 36.54it/s]\n",
            "[26 / 50] Train: Loss = 0.10231, Accuracy = 99.82%: 100%|██████████| 572/572 [00:18<00:00, 31.19it/s]\n",
            "[26 / 50]   Val: Loss = 11.56892, Accuracy = 92.75%: 100%|██████████| 13/13 [00:00<00:00, 38.80it/s]\n",
            "[27 / 50] Train: Loss = 0.09990, Accuracy = 99.83%: 100%|██████████| 572/572 [00:19<00:00, 28.93it/s]\n",
            "[27 / 50]   Val: Loss = 11.66324, Accuracy = 92.74%: 100%|██████████| 13/13 [00:00<00:00, 31.38it/s]\n",
            "[28 / 50] Train: Loss = 0.11131, Accuracy = 99.81%: 100%|██████████| 572/572 [00:19<00:00, 28.95it/s]\n",
            "[28 / 50]   Val: Loss = 12.03391, Accuracy = 92.68%: 100%|██████████| 13/13 [00:00<00:00, 34.03it/s]\n",
            "[29 / 50] Train: Loss = 0.11296, Accuracy = 99.80%: 100%|██████████| 572/572 [00:19<00:00, 29.94it/s]\n",
            "[29 / 50]   Val: Loss = 12.07668, Accuracy = 92.73%: 100%|██████████| 13/13 [00:00<00:00, 32.99it/s]\n",
            "[30 / 50] Train: Loss = 0.09243, Accuracy = 99.84%: 100%|██████████| 572/572 [00:18<00:00, 30.46it/s]\n",
            "[30 / 50]   Val: Loss = 12.55525, Accuracy = 92.70%: 100%|██████████| 13/13 [00:00<00:00, 36.63it/s]\n",
            "[31 / 50] Train: Loss = 0.08621, Accuracy = 99.84%: 100%|██████████| 572/572 [00:18<00:00, 30.89it/s]\n",
            "[31 / 50]   Val: Loss = 12.54929, Accuracy = 92.77%: 100%|██████████| 13/13 [00:00<00:00, 38.62it/s]\n",
            "[32 / 50] Train: Loss = 0.08473, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.28it/s]\n",
            "[32 / 50]   Val: Loss = 12.80744, Accuracy = 92.76%: 100%|██████████| 13/13 [00:00<00:00, 31.71it/s]\n",
            "[33 / 50] Train: Loss = 0.08488, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.54it/s]\n",
            "[33 / 50]   Val: Loss = 13.06749, Accuracy = 92.78%: 100%|██████████| 13/13 [00:00<00:00, 34.72it/s]\n",
            "[34 / 50] Train: Loss = 0.08652, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.55it/s]\n",
            "[34 / 50]   Val: Loss = 13.23488, Accuracy = 92.69%: 100%|██████████| 13/13 [00:00<00:00, 33.21it/s]\n",
            "[35 / 50] Train: Loss = 0.11893, Accuracy = 99.78%: 100%|██████████| 572/572 [00:19<00:00, 30.09it/s]\n",
            "[35 / 50]   Val: Loss = 13.18751, Accuracy = 92.68%: 100%|██████████| 13/13 [00:00<00:00, 36.87it/s]\n",
            "[36 / 50] Train: Loss = 0.11442, Accuracy = 99.79%: 100%|██████████| 572/572 [00:18<00:00, 30.35it/s]\n",
            "[36 / 50]   Val: Loss = 13.09920, Accuracy = 92.80%: 100%|██████████| 13/13 [00:00<00:00, 37.67it/s]\n",
            "[37 / 50] Train: Loss = 0.08390, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.20it/s]\n",
            "[37 / 50]   Val: Loss = 13.36155, Accuracy = 92.82%: 100%|██████████| 13/13 [00:00<00:00, 32.42it/s]\n",
            "[38 / 50] Train: Loss = 0.07779, Accuracy = 99.85%: 100%|██████████| 572/572 [00:18<00:00, 30.14it/s]\n",
            "[38 / 50]   Val: Loss = 13.54898, Accuracy = 92.84%: 100%|██████████| 13/13 [00:00<00:00, 35.96it/s]\n",
            "[39 / 50] Train: Loss = 0.07643, Accuracy = 99.85%: 100%|██████████| 572/572 [00:18<00:00, 30.39it/s]\n",
            "[39 / 50]   Val: Loss = 13.72866, Accuracy = 92.79%: 100%|██████████| 13/13 [00:00<00:00, 31.84it/s]\n",
            "[40 / 50] Train: Loss = 0.07962, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 28.97it/s]\n",
            "[40 / 50]   Val: Loss = 13.75231, Accuracy = 92.80%: 100%|██████████| 13/13 [00:00<00:00, 34.71it/s]\n",
            "[41 / 50] Train: Loss = 0.08030, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.62it/s]\n",
            "[41 / 50]   Val: Loss = 13.83594, Accuracy = 92.74%: 100%|██████████| 13/13 [00:00<00:00, 35.58it/s]\n",
            "[42 / 50] Train: Loss = 0.13322, Accuracy = 99.76%: 100%|██████████| 572/572 [00:19<00:00, 29.56it/s]\n",
            "[42 / 50]   Val: Loss = 14.05392, Accuracy = 92.56%: 100%|██████████| 13/13 [00:00<00:00, 31.23it/s]\n",
            "[43 / 50] Train: Loss = 0.09226, Accuracy = 99.83%: 100%|██████████| 572/572 [00:18<00:00, 30.55it/s]\n",
            "[43 / 50]   Val: Loss = 13.81842, Accuracy = 92.87%: 100%|██████████| 13/13 [00:00<00:00, 37.05it/s]\n",
            "[44 / 50] Train: Loss = 0.07718, Accuracy = 99.85%: 100%|██████████| 572/572 [00:18<00:00, 30.47it/s]\n",
            "[44 / 50]   Val: Loss = 14.35423, Accuracy = 92.81%: 100%|██████████| 13/13 [00:00<00:00, 33.98it/s]\n",
            "[45 / 50] Train: Loss = 0.07507, Accuracy = 99.85%: 100%|██████████| 572/572 [00:18<00:00, 30.72it/s]\n",
            "[45 / 50]   Val: Loss = 14.36844, Accuracy = 92.80%: 100%|██████████| 13/13 [00:00<00:00, 37.39it/s]\n",
            "[46 / 50] Train: Loss = 0.07501, Accuracy = 99.85%: 100%|██████████| 572/572 [00:18<00:00, 31.51it/s]\n",
            "[46 / 50]   Val: Loss = 14.78538, Accuracy = 92.78%: 100%|██████████| 13/13 [00:00<00:00, 40.48it/s]\n",
            "[47 / 50] Train: Loss = 0.07595, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 29.93it/s]\n",
            "[47 / 50]   Val: Loss = 14.86451, Accuracy = 92.79%: 100%|██████████| 13/13 [00:00<00:00, 33.47it/s]\n",
            "[48 / 50] Train: Loss = 0.07568, Accuracy = 99.84%: 100%|██████████| 572/572 [00:19<00:00, 28.83it/s]\n",
            "[48 / 50]   Val: Loss = 15.07312, Accuracy = 92.81%: 100%|██████████| 13/13 [00:00<00:00, 35.37it/s]\n",
            "[49 / 50] Train: Loss = 0.11592, Accuracy = 99.78%: 100%|██████████| 572/572 [00:19<00:00, 29.51it/s]\n",
            "[49 / 50]   Val: Loss = 15.33268, Accuracy = 92.72%: 100%|██████████| 13/13 [00:00<00:00, 32.56it/s]\n",
            "[50 / 50] Train: Loss = 0.10933, Accuracy = 99.80%: 100%|██████████| 572/572 [00:18<00:00, 30.33it/s]\n",
            "[50 / 50]   Val: Loss = 15.08788, Accuracy = 92.83%: 100%|██████████| 13/13 [00:00<00:00, 39.26it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wD56oRpqJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "colab": {}
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create me>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <use me>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {}
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {}
      },
      "source": [
        "<calc test accuracy>"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week 06 - RNNs, part 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U6O2DwKpqHm",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {}
      },
      "source": [
        "!pip3 -qq install torch #==0.4.1\n",
        "!pip3 -qq install bokeh #==0.13.0\n",
        "!pip3 -qq install gensim #==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn #==0.20.2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "cda8087d-de47-41df-da58-13acac306219"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "c1161666-1797-49fa-bdf8-c5fbe0ac8086"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f9fe46fc-b182-4301-ce52-30ed1293951a"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1c2521a1-cb5b-42ae-94c2-f8a74561f0f8"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'PRON', '.', 'ADP', 'DET', 'VERB', 'PRT', 'NOUN', 'ADJ', 'NUM', 'CONJ', 'ADV', 'X'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "824ba5ec-b338-4eb1-f5cb-ecb135ed2d1d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmkAAAEvCAYAAAAemFY+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdcElEQVR4nO3dfbRldX3f8fenM8VlkhpQJoTw4KAOKlgzkVnKSjRBER1IlmAW0ZkmMlrq6BJWCrWpmKTFRm0xiZ0uGsWFYQKkhodIDNQ1Bqeo0bSiDILIoMCAKDPlKaDSRCuC3/5xflc3lzMzd+7j7w7v11pn3X2+++F8z7nnnPu5e+/fOakqJEmS1Jd/stANSJIk6YkMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdWrrQDcy2/fffv5YvX77QbUiSJO3W9ddf//dVtWzcvL0upC1fvpwtW7YsdBuSJEm7leQbO5vn4U5JkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUO7DWlJNia5P8nNg9plSW5sl7uS3Njqy5N8bzDvQ4N1jkrylSTbkpybJK3+9CSbk9zefu7X6mnLbUtyU5IXzf7dlyRJ6tNU9qRdCKweFqrq9VW1sqpWAlcAfzWYfcfEvKp666B+HvBmYEW7TGzzLOCaqloBXNOuAxw/WHZ9W1+SJOlJYbchrao+Czw0bl7bG/Y64JJdbSPJgcDTquraqirgYuCkNvtE4KI2fdGk+sU1ci2wb9uOJEnSXm+m3935MuC+qrp9UDssyQ3Aw8DvV9XngIOA7YNltrcawAFVdU+bvhc4oE0fBNw9Zp17kKRFZMPm26a97pnHHT6LnUhaTGYa0tby+L1o9wCHVtWDSY4C/jrJkVPdWFVVktrTJpKsZ3RIlEMPPXRPV5ckSerOtEd3JlkK/Dpw2UStqr5fVQ+26euBO4DDgR3AwYPVD241gPsmDmO2n/e3+g7gkJ2s8zhVdX5VraqqVcuWLZvuXZIkSerGTD6C45XA16rqR4cxkyxLsqRNP4vRSf93tsOZDyc5up3HdgpwZVvtKmBdm143qX5KG+V5NPCdwWFRSZKkvdpUPoLjEuDzwHOTbE9yapu1hicOGPhl4Kb2kRwfBd5aVRODDt4G/CmwjdEetk+0+jnAcUluZxT8zmn1TcCdbfkPt/UlSZKeFHZ7TlpVrd1J/Y1jalcw+kiOcctvAV4wpv4gcOyYegGn7a4/SZKkvZHfOCBJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1aLchLcnGJPcnuXlQe1eSHUlubJcTBvPemWRbkluTvHpQX91q25KcNagfluQLrX5Zkn1a/Snt+rY2f/ls3WlJkqTeTWVP2oXA6jH1DVW1sl02ASQ5AlgDHNnW+WCSJUmWAB8AjgeOANa2ZQHe17b1HOBbwKmtfirwrVbf0JaTJEl6UthtSKuqzwIPTXF7JwKXVtX3q+rrwDbgxe2yrarurKpHgEuBE5MEeAXw0bb+RcBJg21d1KY/ChzblpckSdrrzeSctNOT3NQOh+7XagcBdw+W2d5qO6s/A/h2VT06qf64bbX532nLS5Ik7fWmG9LOA54NrATuAd4/ax1NQ5L1SbYk2fLAAw8sZCuSJEmzYlohraruq6rHquqHwIcZHc4E2AEcMlj04FbbWf1BYN8kSyfVH7etNv+n2/Lj+jm/qlZV1aply5ZN5y5JkiR1ZVohLcmBg6uvBSZGfl4FrGkjMw8DVgBfBK4DVrSRnPswGlxwVVUV8Gng5Lb+OuDKwbbWtemTgU+15SVJkvZ6S3e3QJJLgGOA/ZNsB84GjkmyEijgLuAtAFW1NcnlwC3Ao8BpVfVY287pwNXAEmBjVW1tN/EO4NIk7wFuAC5o9QuAP0+yjdHAhTUzvreSJEmLxG5DWlWtHVO+YExtYvn3Au8dU98EbBpTv5MfHy4d1v8f8Bu760+SJGlv5DcOSJIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR3abUhLsjHJ/UluHtT+KMnXktyU5GNJ9m315Um+l+TGdvnQYJ2jknwlybYk5yZJqz89yeYkt7ef+7V62nLb2u28aPbvviRJUp+msiftQmD1pNpm4AVV9ULgNuCdg3l3VNXKdnnroH4e8GZgRbtMbPMs4JqqWgFc064DHD9Ydn1bX5Ik6UlhtyGtqj4LPDSp9smqerRdvRY4eFfbSHIg8LSquraqCrgYOKnNPhG4qE1fNKl+cY1cC+zbtiNJkrTXm41z0v4l8InB9cOS3JDkb5O8rNUOArYPltneagAHVNU9bfpe4IDBOnfvZB1JkqS92tKZrJzk94BHgY+00j3AoVX1YJKjgL9OcuRUt1dVlaSm0cd6RodEOfTQQ/d0dUmSpO5Me09akjcCvwb8ZjuESVV9v6oebNPXA3cAhwM7ePwh0YNbDeC+icOY7ef9rb4DOGQn6zxOVZ1fVauqatWyZcume5ckSZK6Ma2QlmQ18O+A11TVdwf1ZUmWtOlnMTrp/852OPPhJEe3UZ2nAFe21a4C1rXpdZPqp7RRnkcD3xkcFpUkSdqr7fZwZ5JLgGOA/ZNsB85mNJrzKcDm9kka17aRnL8M/EGSHwA/BN5aVRODDt7GaKToUxmdwzZxHts5wOVJTgW+Abyu1TcBJwDbgO8Cb5rJHZUkSVpMdhvSqmrtmPIFO1n2CuCKnczbArxgTP1B4Ngx9QJO211/kiRJeyO/cUCSJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOjSj7+6UtLht2HzbjNY/87jDZ6kTSdJk7kmTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjo0pZCWZGOS+5PcPKg9PcnmJLe3n/u1epKcm2RbkpuSvGiwzrq2/O1J1g3qRyX5Slvn3CTZ1W1IkiTt7aa6J+1CYPWk2lnANVW1ArimXQc4HljRLuuB82AUuICzgZcALwbOHoSu84A3D9ZbvZvbkCRJ2qtNKaRV1WeBhyaVTwQuatMXAScN6hfXyLXAvkkOBF4NbK6qh6rqW8BmYHWb97SquraqCrh40rbG3YYkSdJebSbnpB1QVfe06XuBA9r0QcDdg+W2t9qu6tvH1Hd1G4+TZH2SLUm2PPDAA9O8O5IkSf2YlYEDbQ9Yzca2pnMbVXV+Va2qqlXLli2byzYkSZLmxUxC2n3tUCXt5/2tvgM4ZLDcwa22q/rBY+q7ug1JkqS92kxC2lXAxAjNdcCVg/opbZTn0cB32iHLq4FXJdmvDRh4FXB1m/dwkqPbqM5TJm1r3G1IkiTt1ZZOZaEklwDHAPsn2c5olOY5wOVJTgW+AbyuLb4JOAHYBnwXeBNAVT2U5N3AdW25P6iqicEIb2M0gvSpwCfahV3chiRJ0l5tSiGtqtbuZNaxY5Yt4LSdbGcjsHFMfQvwgjH1B8fdhiRJ0t7ObxyQJEnqkCFNkiSpQ4Y0SZKkDk3pnDQtfhs23zaj9c887vBZ6kSSJE2Fe9IkSZI6ZEiTJEnqkIc71a2ZHKL18KwkabFzT5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdcjPSZNmkZ/tJkmaLe5JkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOjTtkJbkuUluHFweTnJGkncl2TGonzBY551JtiW5NcmrB/XVrbYtyVmD+mFJvtDqlyXZZ/p3VZIkafGYdkirqluramVVrQSOAr4LfKzN3jAxr6o2ASQ5AlgDHAmsBj6YZEmSJcAHgOOBI4C1bVmA97VtPQf4FnDqdPuVJElaTGbrcOexwB1V9Y1dLHMicGlVfb+qvg5sA17cLtuq6s6qegS4FDgxSYBXAB9t618EnDRL/UqSJHVttkLaGuCSwfXTk9yUZGOS/VrtIODuwTLbW21n9WcA366qRyfVJUmS9nozDmntPLHXAH/ZSucBzwZWAvcA75/pbUyhh/VJtiTZ8sADD8z1zUmSJM252diTdjzwpaq6D6Cq7quqx6rqh8CHGR3OBNgBHDJY7+BW21n9QWDfJEsn1Z+gqs6vqlVVtWrZsmWzcJckSZIW1myEtLUMDnUmOXAw77XAzW36KmBNkqckOQxYAXwRuA5Y0UZy7sPo0OlVVVXAp4GT2/rrgCtnoV9JkqTuLd39IjuX5CeB44C3DMp/mGQlUMBdE/OqamuSy4FbgEeB06rqsbad04GrgSXAxqra2rb1DuDSJO8BbgAumEm/kiRJi8WMQlpV/SOjE/yHtTfsYvn3Au8dU98EbBpTv5MfHy6VJEl60vAbByRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDSxe6AUlSXzZsvm1G65953OGz1In05DbjPWlJ7krylSQ3JtnSak9PsjnJ7e3nfq2eJOcm2ZbkpiQvGmxnXVv+9iTrBvWj2va3tXUz054lSZJ6N1uHO19eVSuralW7fhZwTVWtAK5p1wGOB1a0y3rgPBiFOuBs4CXAi4GzJ4JdW+bNg/VWz1LPkiRJ3Zqrc9JOBC5q0xcBJw3qF9fItcC+SQ4EXg1srqqHqupbwGZgdZv3tKq6tqoKuHiwLUmSpL3WbIS0Aj6Z5Pok61vtgKq6p03fCxzQpg8C7h6su73VdlXfPqYuSZK0V5uNgQMvraodSX4G2Jzka8OZVVVJahZuZ6daOFwPcOihh87lTUmSJM2LGe9Jq6od7ef9wMcYnVN2XztUSft5f1t8B3DIYPWDW21X9YPH1Cf3cH5VraqqVcuWLZvpXZIkSVpwMwppSX4yyT+bmAZeBdwMXAVMjNBcB1zZpq8CTmmjPI8GvtMOi14NvCrJfm3AwKuAq9u8h5Mc3UZ1njLYliRJ0l5rpoc7DwA+1j4VYynwF1X1N0muAy5PcirwDeB1bflNwAnANuC7wJsAquqhJO8GrmvL/UFVPdSm3wZcCDwV+ES7SJIk7dVmFNKq6k7g58fUHwSOHVMv4LSdbGsjsHFMfQvwgpn0KUmStNj4tVCSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkdMqRJkiR1yJAmSZLUIUOaJElSh5YudAOSJKl/GzbfNqP1zzzu8Fnq5MnDPWmSJEkdMqRJkiR1yJAmSZLUIUOaJElShwxpkiRJHTKkSZIkdciP4JgGhyFLkqS55p40SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUPTDmlJDkny6SS3JNma5F+3+ruS7EhyY7ucMFjnnUm2Jbk1yasH9dWtti3JWYP6YUm+0OqXJdlnuv1KkiQtJjPZk/Yo8PaqOgI4GjgtyRFt3oaqWtkumwDavDXAkcBq4INJliRZAnwAOB44Alg72M772raeA3wLOHUG/UqSJC0a0w5pVXVPVX2pTf9f4KvAQbtY5UTg0qr6flV9HdgGvLhdtlXVnVX1CHApcGKSAK8APtrWvwg4abr9SpIkLSazck5akuXALwBfaKXTk9yUZGOS/VrtIODuwWrbW21n9WcA366qRyfVJUmS9nozDmlJfgq4Ajijqh4GzgOeDawE7gHeP9PbmEIP65NsSbLlgQcemOubkyRJmnMz+saBJP+UUUD7SFX9FUBV3TeY/2Hg4+3qDuCQweoHtxo7qT8I7JtkadubNlz+carqfOB8gFWrVtVM7pMkSfNhJt9e4zfXPDnMZHRngAuAr1bVfxnUDxws9lrg5jZ9FbAmyVOSHAasAL4IXAesaCM592E0uOCqqirg08DJbf11wJXT7VeSJGkxmcmetF8C3gB8JcmNrfa7jEZnrgQKuAt4C0BVbU1yOXALo5Ghp1XVYwBJTgeuBpYAG6tqa9veO4BLk7wHuIFRKJQkSdrrTTukVdXfARkza9Mu1nkv8N4x9U3j1quqOxmN/pQkSXpS8RsHJEmSOmRIkyRJ6pAhTZIkqUOGNEmSpA7N6HPSJGm+zeSzpcDPl5K0eLgnTZIkqUOGNEmSpA4Z0iRJkjpkSJMkSeqQIU2SJKlDhjRJkqQOGdIkSZI6ZEiTJEnqkCFNkiSpQ4Y0SZKkDhnSJEmSOmRIkyRJ6pAhTZIkqUNLF7oBSZJmasPm22a0/pnHHT5LnUizxz1pkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR0ypEmSJHXIkCZJktQhQ5okSVKHDGmSJEkd6j6kJVmd5NYk25KctdD9SJIkzYeuQ1qSJcAHgOOBI4C1SY5Y2K4kSZLmXtchDXgxsK2q7qyqR4BLgRMXuCdJkqQ51/sXrB8E3D24vh14yQL1IkmSFpENm2+b0fpnHnf4LHUyPamqBW1gV5KcDKyuqn/Vrr8BeElVnT5pufXA+nb1ucCt89roE+0P/P0C97Cn7HnuLbZ+wZ7nw2LrF+x5viy2nhdbv9BHz8+sqmXjZvS+J20HcMjg+sGt9jhVdT5w/nw1tTtJtlTVqoXuY0/Y89xbbP2CPc+HxdYv2PN8WWw9L7Z+of+eez8n7TpgRZLDkuwDrAGuWuCeJEmS5lzXe9Kq6tEkpwNXA0uAjVW1dYHbkiRJmnNdhzSAqtoEbFroPvZQN4de94A9z73F1i/Y83xYbP2CPc+XxdbzYusXOu+564EDkiRJT1a9n5MmSZL0pGRI240kjyW5McnNSf4yyU+Mqf+PJPsO1jkyyafa11ndnuTfJ0mb98YkP0zywsHyNydZPt/3rWdJTkpSSZ7Xri9P8r0kNyT5apIvJnnjYPk3Jnmg/U5uSfLmee534vmwNcmXk7w9yT9p845J8p02f+Ly+sH0vUl2DK7vM0c9fjrJqyfVzkjyifbYDvs7pc2/K8lXktyU5G+TPHPMff5yki8l+cW56HvM/ZjyazLJF1rtm4Pnx41z8Xprz9f3D67/2yTvGlxfn+Rr7fLFJC8dzLsryf6D68ck+XibXpD3jGm+Bv9kLnsa0+NOH/MkF2b0MU7D5f+h/Vze1n3PYN7+SX4w1/chyc8muTTJHUmuT7IpyeGZwd+Nyc+fOex9ys+JJL+S5POT1l+a5L4kPzfXve5KkkOSfD3J09v1/dr15QvZ1ziGtN37XlWtrKoXAI8Abx1Tfwg4DSDJUxmNQD2nqp4L/Dzwi8DbBtvcDvzefN2BRWot8Hft54Q7quoXqur5jEb6npHkTYP5l1XVSuAY4D8lOWDeuv3x8+FI4DhGX2V29mD+59r8ictlE9PAh4ANg3mPzFGPlzB63IbWAP+Z0WM77O/iwTIvr6oXAp8Bfn9Qn7jPPw+8s21nPkz5NVlVL2mP8X+gPT/a5a456Ov7wK+P+2OZ5NeAtwAvrarntZ7/IsnPTnHbC/GeMZ3X4Hzb6WM+BV8HfnVw/TeAOR2Y1kLXx4DPVNWzq+ooRq+dA1gcfzf25DnxOeDg4T92wCuBrVX1f+at4zGq6m7gPOCcVjoHOH+O3hdmxJC2Zz4HPGdM/fOMvh0B4F8A/6uqPglQVd8FTgeGXw7/ceDIJM+dw14XrSQ/BbwUOJUnhgoAqupO4N8Avz1m3v3AHcAzJ8+bD+321wOnT/wn3ImPAr+atqeu/df4czz+Wz12Zfg8n+xpwLdm2N90TOU1OV8eZXQS8plj5r0D+J2q+nuAqvoScBHtn7spmNf3jJm+BufRrh7z3fku8NUkE5+R9Xrg8tlqbCdeDvygqj40UaiqLwOH0/nfjT19TlTVDxk9nsNl1zD6Z7EHG4Cjk5zB6H798QL3M5YhbYqSLGW0d+Qrk+pLgGP58ee3HQlcP1ymqu4AfirJ01rph8AfAr87lz0vYicCf1NVtwEPJjlqJ8t9CXje5GKSZwHPArbNXYu71t6slgA/00ovy+MPJz57AXp6CPgio+cxjN4wLwcKePak/l42ZhOrgb8eXH9qW/ZrwJ8C757D9p9gD16T8+kDwG8m+elJ9Se8LwBbWn0q5vs9Y0avwXm2s8d8Ki4F1iQ5BHgMmOs9PC/gic8DWBx/N6bznPjR3vskTwFOAK6Y60anoqp+APwOo7B2RrveHUPa7j01yY2M3lC/CVwwqX4vo13Vm/dwu3/BKMUfNmud7j3WMnrzpP1cu5PlJu+len37nVwCvKWFkl5MPtx5xwL1MTzkOfyvdvLhzs8N1vl0kh2MAtHwv+CJw4vPYxTgLp6nPYdz9Zqcsap6GLiYPd+7NG6Y/eTafL5nTPc1OO928ZhP5TH9G0anJ6wBLpv97mbdQv7d2OPnRFVtYRQ0n8vo/eMLnb0vHw/cwyg8d6n7z0nrwPfaOS1j6xmdtHw1o8MW5wK3AL88XLDt2fmHqnp44m9Y+6De9zM6DKKmncj5CuCfJylGe6OK0X/Lk/0C8NXB9csmf6/rQmm/88eA+4HnL3A7Q1cCG5K8CPiJqrp+CifLvhz4NvAR4D8yOpzxOFX1+XZe0DJG93ku7elrcr79V0Z7E/5sULsFOAr41KB2FD8+B+pBYD9+/B2CT2fS9wnO13vGDF+DC2XcYz7xmAI/ul+TH9NHklwPvB04AnjNHPe5FTh5TL3rvxszfE5M/GP4fPo51EmSlYwC+tHA3yW5tKruWeC2nsA9aTPUzh34beDt7fDLR4CXJnkl/GggwbmMdlNPdiGjEynHfrHqk9TJwJ9X1TOranlVHcLoBN/hd7hOnE/1x8B/m/cOdyPJMkaDAf6kOvsgwqr6B+DTwEb24A2zqh4FzgBOmRgRNdRGey1h9IdxQY15Tc737T/E6DDyqYPyHwLvS/IM+NEfiDcCH2zzPwO8oc1bAvwWo9/TZBcy9+8Zi+41uJPH/DOM9q5PjJZ+I+Mf0/cD75inPTyfAp6SZP1EoY3YvJW+/27M5DlxCaPn8ysY/ZO44Noe//MYHeb8JvBHeE7a3quqbgBuAtZW1fcYHbv//SS3Mjpf5jrgCcO62yi+c/nxeUsLIqMh4As6JHpgLaPRT0NXMBoB9eyJod6M3pDPrao/m7yBBTJxftZW4H8Cn2S012nC5HPSxv03PV8uYTR6bBjSJp+TNm5Axj1tnYmT3Sfu842MDhWtq6rH5rr5qRi+JheohfcDPxpxWFVXMQrG/7udw/dh4LcG/7m/G3hOki8DNzA6n/K/T97oPL1nTPc1uJTRaMuFMvkx/zijgSXXt+foLzFmD1RVba2qi+ajwfZP22uBV2b0ERxbGY2KvpeZ/d2Y68d+2u/LVfVV4B+BT1XVP85hj3vizcA3q2rilIgPAs9P8isL2NNYfuOAJGnGkmwAbq+qD+52Yc2atuf+xqqa79HMmgfuSZMkzUiSTwAvZHS6h+ZJktcw2lv4zoXuRXPDPWmSJEkdck+aJElShwxpkiRJHTKkSZIkdciQJkmS1CFDmiRJUocMaZIkSR36/9ddhLXkKTVhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9d3a2495-0b43-486c-aa7e-ca0b0dac9b5e"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c9c91526-e28f-433e-f52b-a88a06ab4a98"
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "446b4f8d-1d43-4f2f-f032-d7aa4cb17b61"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b7aad8f8-3253-4761-9460-3de7472fe85d"
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers = lstm_layers_count)\n",
        "        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, self.hidden = self.lstm(embeds)\n",
        "        tag_res = self.hidden2tag(lstm_out)\n",
        "        # tag_res = F.softmax(tag_res)\n",
        "\n",
        "        return tag_res"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66370552-4724-41f0-e890-c3bb111056f6"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "preds = torch.argmax(logits, dim = -1)\n",
        "mask = (y_batch != 0).float() ## for deleting the padding\n",
        "\n",
        "correct_preds = ((preds == y_batch).float() * mask).sum().item() ## correct predictions\n",
        "total_preds = (y_batch != 0).float().sum().item()\n",
        "print(correct_preds / total_preds)\n",
        "# <calc accuracy>"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06521739130434782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "212cd072-7f0b-438e-e106-be1b7e3ade07"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = 0\n",
        "for i, elem in enumerate(logits):\n",
        "    loss += criterion(elem, y_batch[i])\n",
        "    \n",
        "loss"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(82.5156, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = 0\n",
        "                for i, elem in enumerate(logits):\n",
        "                    loss += criterion(elem, y_batch[i])\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                mask = (y_batch != 0).float()\n",
        "                preds = torch.argmax(logits, dim = -1)\n",
        "                preds = ((preds == y_batch).float() * mask).sum().item()\n",
        "                total = mask.sum().item()\n",
        "                cur_correct_count, cur_sum_count = preds, total\n",
        "\n",
        "                # preds = torch.argmax(logits, dim=-1)\n",
        "                # mask = (y_batch != 0).float()\n",
        "                \n",
        "                # cur_correct_count, cur_sum_count = ((preds == y_batch).float() * mask).sum().item(), mask.sum().item()\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "outputId": "ff2bf33e-5db3-4ab3-bc8f-c9793886a241"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 20] Train: Loss = 19.19218, Accuracy = 72.01%: 100%|██████████| 572/572 [00:14<00:00, 40.19it/s]\n",
            "[1 / 20]   Val: Loss = 9.52944, Accuracy = 85.59%: 100%|██████████| 13/13 [00:00<00:00, 51.63it/s]\n",
            "[2 / 20] Train: Loss = 6.09801, Accuracy = 90.19%: 100%|██████████| 572/572 [00:14<00:00, 39.10it/s]\n",
            "[2 / 20]   Val: Loss = 7.14311, Accuracy = 89.95%: 100%|██████████| 13/13 [00:00<00:00, 47.30it/s]\n",
            "[3 / 20] Train: Loss = 4.11388, Accuracy = 93.35%: 100%|██████████| 572/572 [00:14<00:00, 40.28it/s]\n",
            "[3 / 20]   Val: Loss = 6.29958, Accuracy = 91.56%: 100%|██████████| 13/13 [00:00<00:00, 50.25it/s]\n",
            "[4 / 20] Train: Loss = 3.13335, Accuracy = 94.86%: 100%|██████████| 572/572 [00:14<00:00, 39.91it/s]\n",
            "[4 / 20]   Val: Loss = 6.11623, Accuracy = 92.26%: 100%|██████████| 13/13 [00:00<00:00, 54.46it/s]\n",
            "[5 / 20] Train: Loss = 2.50647, Accuracy = 95.86%: 100%|██████████| 572/572 [00:14<00:00, 40.61it/s]\n",
            "[5 / 20]   Val: Loss = 5.93597, Accuracy = 92.83%: 100%|██████████| 13/13 [00:00<00:00, 52.65it/s]\n",
            "[6 / 20] Train: Loss = 2.04775, Accuracy = 96.57%: 100%|██████████| 572/572 [00:14<00:00, 39.80it/s]\n",
            "[6 / 20]   Val: Loss = 6.00826, Accuracy = 93.17%: 100%|██████████| 13/13 [00:00<00:00, 52.00it/s]\n",
            "[7 / 20] Train: Loss = 1.69331, Accuracy = 97.16%: 100%|██████████| 572/572 [00:14<00:00, 39.62it/s]\n",
            "[7 / 20]   Val: Loss = 6.11025, Accuracy = 93.27%: 100%|██████████| 13/13 [00:00<00:00, 52.84it/s]\n",
            "[8 / 20] Train: Loss = 1.40853, Accuracy = 97.62%: 100%|██████████| 572/572 [00:14<00:00, 39.92it/s]\n",
            "[8 / 20]   Val: Loss = 6.30421, Accuracy = 93.38%: 100%|██████████| 13/13 [00:00<00:00, 51.60it/s]\n",
            "[9 / 20] Train: Loss = 1.16961, Accuracy = 98.03%: 100%|██████████| 572/572 [00:14<00:00, 39.53it/s]\n",
            "[9 / 20]   Val: Loss = 6.51942, Accuracy = 93.49%: 100%|██████████| 13/13 [00:00<00:00, 47.88it/s]\n",
            "[10 / 20] Train: Loss = 0.96538, Accuracy = 98.38%: 100%|██████████| 572/572 [00:14<00:00, 39.92it/s]\n",
            "[10 / 20]   Val: Loss = 6.67816, Accuracy = 93.46%: 100%|██████████| 13/13 [00:00<00:00, 50.83it/s]\n",
            "[11 / 20] Train: Loss = 0.79767, Accuracy = 98.67%: 100%|██████████| 572/572 [00:14<00:00, 39.83it/s]\n",
            "[11 / 20]   Val: Loss = 6.88913, Accuracy = 93.46%: 100%|██████████| 13/13 [00:00<00:00, 54.12it/s]\n",
            "[12 / 20] Train: Loss = 0.65173, Accuracy = 98.94%: 100%|██████████| 572/572 [00:14<00:00, 39.79it/s]\n",
            "[12 / 20]   Val: Loss = 7.32733, Accuracy = 93.45%: 100%|██████████| 13/13 [00:00<00:00, 52.56it/s]\n",
            "[13 / 20] Train: Loss = 0.52433, Accuracy = 99.16%: 100%|██████████| 572/572 [00:14<00:00, 39.51it/s]\n",
            "[13 / 20]   Val: Loss = 7.66844, Accuracy = 93.41%: 100%|██████████| 13/13 [00:00<00:00, 52.62it/s]\n",
            "[14 / 20] Train: Loss = 0.42786, Accuracy = 99.33%: 100%|██████████| 572/572 [00:14<00:00, 39.99it/s]\n",
            "[14 / 20]   Val: Loss = 7.97548, Accuracy = 93.43%: 100%|██████████| 13/13 [00:00<00:00, 50.77it/s]\n",
            "[15 / 20] Train: Loss = 0.33821, Accuracy = 99.49%: 100%|██████████| 572/572 [00:14<00:00, 39.73it/s]\n",
            "[15 / 20]   Val: Loss = 8.29499, Accuracy = 93.39%: 100%|██████████| 13/13 [00:00<00:00, 50.15it/s]\n",
            "[16 / 20] Train: Loss = 0.27364, Accuracy = 99.60%: 100%|██████████| 572/572 [00:14<00:00, 39.40it/s]\n",
            "[16 / 20]   Val: Loss = 8.76871, Accuracy = 93.35%: 100%|██████████| 13/13 [00:00<00:00, 51.55it/s]\n",
            "[17 / 20] Train: Loss = 0.22638, Accuracy = 99.67%: 100%|██████████| 572/572 [00:14<00:00, 40.02it/s]\n",
            "[17 / 20]   Val: Loss = 9.10570, Accuracy = 93.38%: 100%|██████████| 13/13 [00:00<00:00, 49.20it/s]\n",
            "[18 / 20] Train: Loss = 0.18757, Accuracy = 99.73%: 100%|██████████| 572/572 [00:14<00:00, 39.82it/s]\n",
            "[18 / 20]   Val: Loss = 9.56703, Accuracy = 93.34%: 100%|██████████| 13/13 [00:00<00:00, 53.01it/s]\n",
            "[19 / 20] Train: Loss = 0.15702, Accuracy = 99.78%: 100%|██████████| 572/572 [00:14<00:00, 39.83it/s]\n",
            "[19 / 20]   Val: Loss = 9.81645, Accuracy = 93.29%: 100%|██████████| 13/13 [00:00<00:00, 49.99it/s]\n",
            "[20 / 20] Train: Loss = 0.14142, Accuracy = 99.79%: 100%|██████████| 572/572 [00:14<00:00, 39.23it/s]\n",
            "[20 / 20]   Val: Loss = 10.23569, Accuracy = 93.25%: 100%|██████████| 13/13 [00:00<00:00, 51.83it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "colab": {}
      },
      "source": [
        "def accuracy(model, data, batch_size = 64):\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    model.eval()\n",
        "    for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size = 64)):\n",
        "        X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "        preds = model(X_batch)\n",
        "        preds = torch.argmax(preds, dim = -1)\n",
        "\n",
        "        mask = (y_batch != 0).float()\n",
        "        correct += ((preds == y_batch).float() * mask).sum().item()\n",
        "\n",
        "        total += mask.sum().item()\n",
        "\n",
        "    return float(correct) / total"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nMSR-MAFLZN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f09c54fc-af81-4711-829b-811ff476cd1c"
      },
      "source": [
        "accuracy(model, (X_test, y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9340377114253157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wD56oRpqJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers = lstm_layers_count, bidirectional = True)\n",
        "        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, self.hidden = self.lstm(embeds)\n",
        "        tag_res = self.hidden2tag(lstm_out)\n",
        "\n",
        "        return tag_res"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mfu8OFaSFWvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "9346e2f1-637c-4924-94ed-32f52b652a00"
      },
      "source": [
        "model = BiLSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=20,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 / 20] Train: Loss = 41.04498, Accuracy = 78.24%: 100%|██████████| 572/572 [00:15<00:00, 36.37it/s]\n",
            "[1 / 20]   Val: Loss = 38.89654, Accuracy = 86.43%: 100%|██████████| 13/13 [00:00<00:00, 46.90it/s]\n",
            "[2 / 20] Train: Loss = 17.84332, Accuracy = 90.37%: 100%|██████████| 572/572 [00:16<00:00, 35.68it/s]\n",
            "[2 / 20]   Val: Loss = 27.36181, Accuracy = 91.03%: 100%|██████████| 13/13 [00:00<00:00, 47.66it/s]\n",
            "[3 / 20] Train: Loss = 11.43523, Accuracy = 93.71%: 100%|██████████| 572/572 [00:15<00:00, 36.39it/s]\n",
            "[3 / 20]   Val: Loss = 22.00043, Accuracy = 93.01%: 100%|██████████| 13/13 [00:00<00:00, 45.75it/s]\n",
            "[4 / 20] Train: Loss = 7.47322, Accuracy = 95.50%: 100%|██████████| 572/572 [00:15<00:00, 36.62it/s]\n",
            "[4 / 20]   Val: Loss = 18.36933, Accuracy = 94.11%: 100%|██████████| 13/13 [00:00<00:00, 47.35it/s]\n",
            "[5 / 20] Train: Loss = 5.10288, Accuracy = 96.66%: 100%|██████████| 572/572 [00:15<00:00, 36.59it/s]\n",
            "[5 / 20]   Val: Loss = 17.48920, Accuracy = 94.43%: 100%|██████████| 13/13 [00:00<00:00, 46.56it/s]\n",
            "[6 / 20] Train: Loss = 3.51642, Accuracy = 97.47%: 100%|██████████| 572/572 [00:15<00:00, 35.98it/s]\n",
            "[6 / 20]   Val: Loss = 16.28908, Accuracy = 95.01%: 100%|██████████| 13/13 [00:00<00:00, 45.64it/s]\n",
            "[7 / 20] Train: Loss = 2.56394, Accuracy = 98.08%: 100%|██████████| 572/572 [00:15<00:00, 36.41it/s]\n",
            "[7 / 20]   Val: Loss = 17.15087, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 44.51it/s]\n",
            "[8 / 20] Train: Loss = 1.85846, Accuracy = 98.52%: 100%|██████████| 572/572 [00:15<00:00, 36.71it/s]\n",
            "[8 / 20]   Val: Loss = 15.09251, Accuracy = 95.38%: 100%|██████████| 13/13 [00:00<00:00, 46.33it/s]\n",
            "[9 / 20] Train: Loss = 1.32897, Accuracy = 98.88%: 100%|██████████| 572/572 [00:15<00:00, 36.41it/s]\n",
            "[9 / 20]   Val: Loss = 16.21047, Accuracy = 95.36%: 100%|██████████| 13/13 [00:00<00:00, 14.27it/s]\n",
            "[10 / 20] Train: Loss = 0.96302, Accuracy = 99.16%: 100%|██████████| 572/572 [00:17<00:00, 32.55it/s]\n",
            "[10 / 20]   Val: Loss = 16.92401, Accuracy = 95.56%: 100%|██████████| 13/13 [00:00<00:00, 42.88it/s]\n",
            "[11 / 20] Train: Loss = 0.66634, Accuracy = 99.42%:   9%|▊         | 50/572 [00:01<00:15, 33.87it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVogwZcmFoa5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy(model, (X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "colab": {}
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vxtEOtvF069",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "\n",
        "embedding = Variable(torch.from_numpy(embeddings))\n",
        "embedding = embeddings_t.float().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers = lstm_layers_count, bidirectional = True)\n",
        "        self.hidden2tag = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, self.hidden = self.lstm(embeds)\n",
        "        tag_res = self.hidden2tag(lstm_out)\n",
        "\n",
        "        return tag_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {}
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {}
      },
      "source": [
        "accuracy(model, (X_train, X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE5nibwRqGcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
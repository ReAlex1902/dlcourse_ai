{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Week 06 - RNNs, part 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U6O2DwKpqHm",
        "colab_type": "text"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "P59NYU98GCb9",
        "colab": {}
      },
      "source": [
        "!pip3 -qq install torch #==0.4.1\n",
        "!pip3 -qq install bokeh #==0.13.0\n",
        "!pip3 -qq install gensim #==3.6.0\n",
        "!pip3 -qq install nltk\n",
        "!pip3 -qq install scikit-learn #==0.20.2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8sVtGHmA9aBM",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TiA2dGmgF1rW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a8f7ab12-94ab-450d-8051-906f085e290d"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QstS4NO0L97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "a14eb55a-e9a3-49ba-f016-8a856fcf1fe3"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTai8Ta0lgwL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "0683e5ec-a1f2-422b-aaed-d6ee5abb9de5"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pCjwwDs6Zq9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1be35796-6255-4d47-fa8d-a676f23ecd02"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique words in train = 45441. Tags = {'ADJ', 'ADP', 'PRT', 'NOUN', 'PRON', 'NUM', 'ADV', 'VERB', 'CONJ', '.', 'X', 'DET'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "URC1B2nvPGFt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "59d30818-c144-4703-adba-647fc94fc1e8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5rWmSToIaeAo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bbda54f-c37a-45d9-e080-4dd0625ec460"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')\n",
        "\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vjz_Rk0bbMyH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "383ec5e9-2b9b-4896-f319-820882601504"
      },
      "source": [
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8XCuxEBVbOY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "abcbe5b4-d94f-48bf-c834-7e94c68def50"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RtRbz1SwgEqc",
        "colab": {}
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DhsTKZalfih6",
        "colab": {}
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        \n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4XsRII5kW5x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97085e63-01cc-4e22-a1e2-91187f8f0857"
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((32, 4), (32, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WVEHju54d68T",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self.lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers = lstm_layers_count)\n",
        "        self.hidden2tag = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = self.embedding(inputs)\n",
        "        lstm_out, self.hidden = self.lstm(embeds)\n",
        "        tag_res = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.softmax(tag_res)\n",
        "\n",
        "        return tag_scores"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jbrxsZ2mehWB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "e23edbbf-827b-45db-b619-02311e3ab85e"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "preds = torch.argmax(logits, dim = -1)\n",
        "mask = (y_batch != 0).float() ## for deleting the padding\n",
        "\n",
        "correct_preds = ((preds == y_batch).float() * mask).sum().item() ## correct predictions\n",
        "total_preds = (y_batch != 0).float().sum().item()\n",
        "print(correct_preds / total_preds)\n",
        "# <calc accuracy>"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.043478260869565216\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GMUyUm1hgpe3",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(preds, )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FprPQ0gllo7b",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = <calc loss>\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                cur_correct_count, cur_sum_count = <calc accuracy>\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pqfbeh1ltEYa",
        "colab": {}
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "98wr38_rw55D",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97wD56oRpqJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uZpY_Q1xZ18h",
        "colab": {}
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VsCstxiO03oT",
        "colab": {}
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.vocab:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LxaRBpQd0pat",
        "colab": {}
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        <create me>\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        <use me>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EBtI6BDE-Fc7",
        "colab": {}
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=50,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPUuAPGhEGVR",
        "colab": {}
      },
      "source": [
        "<calc test accuracy>"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}